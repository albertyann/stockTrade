
```markdown
# 股票深度分析系统：系统设计文档

## 1. 系统架构概述

本系统采用**前后端分离架构**，结合微服务思想和现代化技术栈，构建一个高性能、可扩展的股票深度分析平台。系统分为前端展示层、后端服务层、数据存储层和外部API集成层四个主要层次，各层次之间通过标准化接口通信，确保系统的模块化和可维护性。

```
┌─────────────────────────────────────────────────────────────┐
│                    前端展示层 (Frontend)                    │
│ ┌─────────────────────────────────────────────────────────┐│
│ │  Web应用 (React/Vue)  |  移动应用 (React Native/Flutter) ││
│ └─────────────────────────────────────────────────────────┘│
│               ↓ HTTP/HTTPS (RESTful API)                   │
├─────────────────────────────────────────────────────────────┤
│                    后端服务层 (Backend)                     │
│ ┌─────────────────────────────────────────────────────────┐│
│ │  API网关 (API Gateway)                                  ││
│ │  ├─ 用户认证服务 (Auth Service)                         ││
│ │  ├─ 数据同步服务 (Data Sync Service)                    ││
│ │  ├─ 分析规则引擎 (Rule Engine Service)                  ││
│ │  ├─ 股票档案管理服务 (Stock Profile Service)             ││
│ │  └─ 文件管理服务 (File Management Service)               ││
│ └─────────────────────────────────────────────────────────┘│
│               ↓ 内部通信 (HTTP/RPC)                        │
├─────────────────────────────────────────────────────────────┤
│                    数据存储层 (Data Storage)                │
│ ┌─────────────────────────────────────────────────────────┐│
│ │  关系型数据库 (PostgreSQL)  - 用户数据、规则配置         ││
│ │  时序数据库 (InfluxDB/TDengine) - 股票交易数据           ││
│ │  对象存储 (MinIO/AWS S3) - 文件存储 (PDF, Excel, etc.)  ││
│ │  缓存 (Redis) - 热点数据缓存                            ││
│ └─────────────────────────────────────────────────────────┘│
│               ↓                                           │
├─────────────────────────────────────────────────────────────┤
│              外部API集成层 (External APIs)                  │
│ ┌─────────────────────────────────────────────────────────┐│
│ │  股票数据API (Alpha Vantage/Finnhub/Twelve Data)         ││
│ │  财务数据API (Yahoo Finance/Quandl)                     ││
│ │  消息通知服务 (Email/Push Notification)                  ││
│ └─────────────────────────────────────────────────────────┘│
└─────────────────────────────────────────────────────────────┘
```

## 2. 系统模块详细设计

### 2.1 前端展示层

#### 2.1.1 技术选型
- **Web应用**：React + TypeScript + Tailwind CSS
- **移动应用**：React Native (跨平台) 或 Flutter
- **图表库**：ECharts / Chart.js (Web)，Victory Native (移动端)
- **状态管理**：Redux (Web)，MobX (Web) 或 Context API
- **路由**：React Router (Web)，React Navigation (移动端)

#### 2.1.2 页面架构
```
┌─────────────────────────────────────────────────────────────┐
│                     路由结构 (Routes)                       │
│ ┌─────────────────────────────────────────────────────────┐│
│ │ /dashboard              - 仪表板                          ││
│ │ /stocks                 - 股票列表                        ││
│ │ /stocks/:code           - 股票档案库                      ││
│ │   ├─ /profile           - 档案概览                        ││
│ │   ├─ /financials        - 三表深度透视                    ││
│ │   ├─ /notes             - 投资笔记                        ││
│ │   └─ /reports           - 分析报告                        ││
│ │ /rules                  - 分析规则引擎                    ││
│ │ /sync                   - 数据同步管理                    ││
│ │ /settings               - 系统设置                        ││
│ │ /auth                   - 认证 (登录/注册)                ││
│ └─────────────────────────────────────────────────────────┘│
└─────────────────────────────────────────────────────────────┘
```

#### 2.1.3 核心组件库
```javascript
// 示例：股票卡片组件
import React from 'react';
import { StockData } from '../types';

interface StockCardProps {
  stock: StockData;
  onClick: () => void;
}

const StockCard: React.FC<StockCardProps> = ({ stock, onClick }) => {
  const isPositive = stock.change >= 0;
  
  return (
    <div 
      className={`p-4 rounded-lg shadow-md cursor-pointer transition-all hover:shadow-lg ${
        isPositive ? 'bg-green-50 border-l-4 border-green-500' : 'bg-red-50 border-l-4 border-red-500'
      }`}
      onClick={onClick}
    >
      <div className="flex justify-between items-start mb-2">
        <div>
          <h3 className="text-lg font-semibold">{stock.code}</h3>
          <p className="text-sm text-gray-600">{stock.name}</p>
        </div>
        <div className="text-right">
          <p className="text-xl font-bold">{stock.price}</p>
          <p className={`text-sm font-semibold ${
            isPositive ? 'text-green-600' : 'text-red-600'
          }`}>
            {isPositive ? '+' : ''}{stock.change}%
          </p>
        </div>
      </div>
      <div className="flex justify-between text-xs text-gray-500">
        <span>成交量: {stock.volume.toLocaleString()}</span>
        <span>市值: {stock.marketCap}</span>
        <span>PE: {stock.pe}</span>
      </div>
    </div>
  );
};

export default StockCard;
```

### 2.2 后端服务层

#### 2.2.1 技术选型
- **主要语言**：Python (数据处理)，Node.js (API服务) 或 Go (高性能服务)
- **框架**：FastAPI (Python)，Express.js (Node.js) 或 Gin (Go)
- **任务调度**：APScheduler (Python)，node-cron (Node.js)
- **消息队列**：RabbitMQ 或 Redis
- **ORM**：SQLAlchemy (Python)，Sequelize (Node.js) 或 GORM (Go)

#### 2.2.2 核心服务架构

```python
# 示例：数据同步服务 (Python + FastAPI)
from fastapi import APIRouter, Depends
from sqlalchemy.orm import Session
from . import crud, schemas, dependencies
from .services.data_sync_service import DataSyncService

router = APIRouter()

@router.post("/sync/stocks", response_model=schemas.SyncResult)
async def sync_stock_data(
    sync_request: schemas.SyncRequest,
    db: Session = Depends(dependencies.get_db)
):
    """
    同步股票数据
    """
    sync_service = DataSyncService(db)
    result = await sync_service.sync_stock_data(sync_request)
    return result

@router.post("/sync/financials", response_model=schemas.SyncResult)
async def sync_financial_data(
    sync_request: schemas.SyncRequest,
    db: Session = Depends(dependencies.get_db)
):
    """
    同步财务数据
    """
    sync_service = DataSyncService(db)
    result = await sync_service.sync_financial_data(sync_request)
    return result

@router.get("/sync/status", response_model=schemas.SyncStatus)
async def get_sync_status(
    db: Session = Depends(dependencies.get_db)
):
    """
    获取数据同步状态
    """
    sync_service = DataSyncService(db)
    status = await sync_service.get_sync_status()
    return status
```

#### 2.2.3 分析规则引擎
```python
# 示例：规则引擎核心实现
class RuleEngine:
    def __init__(self, db_session):
        self.db = db_session
        
    def evaluate_rule(self, rule: dict, stock_code: str, data: dict) -> bool:
        """
        评估单条规则
        """
        conditions = rule.get("conditions", [])
        logic = rule.get("logic", "AND")
        
        results = []
        for condition in conditions:
            result = self._evaluate_condition(condition, stock_code, data)
            results.append(result)
            
        if logic == "AND":
            return all(results)
        elif logic == "OR":
            return any(results)
        else:
            raise ValueError(f"Unsupported logic operator: {logic}")
            
    def _evaluate_condition(self, condition: dict, stock_code: str, data: dict) -> bool:
        """
        评估单个条件
        """
        indicator = condition.get("indicator")
        operator = condition.get("operator")
        value = condition.get("value")
        
        if indicator == "price":
            return self._compare(data.get("price", 0), operator, value)
        elif indicator == "volume":
            return self._compare(data.get("volume", 0), operator, value)
        elif indicator == "ma20":
            return self._compare(data.get("ma20", 0), operator, value)
        elif indicator == "pe":
            return self._compare(data.get("pe", 0), operator, value)
        elif indicator == "roe":
            return self._compare(data.get("roe", 0), operator, value)
        else:
            raise ValueError(f"Unsupported indicator: {indicator}")
            
    def _compare(self, a: float, operator: str, b: float) -> bool:
        """
        比较操作
        """
        if operator == "gt":
            return a > b
        elif operator == "lt":
            return a < b
        elif operator == "gte":
            return a >= b
        elif operator == "lte":
            return a <= b
        elif operator == "eq":
            return a == b
        elif operator == "neq":
            return a != b
        else:
            raise ValueError(f"Unsupported operator: {operator}")
```

### 2.3 数据存储层

#### 2.3.1 数据库设计

**用户管理表**：
```sql
CREATE TABLE users (
    id SERIAL PRIMARY KEY,
    username VARCHAR(50) UNIQUE NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    password_hash VARCHAR(255) NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);
```

**股票基础信息表**：
```sql
CREATE TABLE stocks (
    id SERIAL PRIMARY KEY,
    code VARCHAR(20) UNIQUE NOT NULL,
    name VARCHAR(100) NOT NULL,
    market VARCHAR(20),
    industry VARCHAR(100),
    description TEXT,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);
```

**股票交易数据表** (时序数据)：
```sql
-- 使用InfluxDB存储交易数据
-- 测量值: stock_trades
-- 标签: code (股票代码), market (市场)
-- 字段: open, high, low, close, volume, amount
```

**用户自选股表**：
```sql
CREATE TABLE user_stocks (
    id SERIAL PRIMARY KEY,
    user_id INTEGER REFERENCES users(id) ON DELETE CASCADE,
    stock_id INTEGER REFERENCES stocks(id) ON DELETE CASCADE,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    UNIQUE(user_id, stock_id)
);
```

**分析规则表**：
```sql
CREATE TABLE analysis_rules (
    id SERIAL PRIMARY KEY,
    user_id INTEGER REFERENCES users(id) ON DELETE CASCADE,
    name VARCHAR(100) NOT NULL,
    description TEXT,
    conditions JSONB NOT NULL,
    priority INTEGER DEFAULT 1,
    enabled BOOLEAN DEFAULT TRUE,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);
```

**投资笔记表**：
```sql
CREATE TABLE investment_notes (
    id SERIAL PRIMARY KEY,
    user_id INTEGER REFERENCES users(id) ON DELETE CASCADE,
    stock_id INTEGER REFERENCES stocks(id) ON DELETE CASCADE,
    title VARCHAR(200) NOT NULL,
    content TEXT,
    tags TEXT[],
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);
```

**文件管理表**：
```sql
CREATE TABLE uploaded_files (
    id SERIAL PRIMARY KEY,
    user_id INTEGER REFERENCES users(id) ON DELETE CASCADE,
    stock_id INTEGER REFERENCES stocks(id) ON DELETE CASCADE,
    file_name VARCHAR(200) NOT NULL,
    file_type VARCHAR(50),
    file_path VARCHAR(500) NOT NULL,
    file_size BIGINT,
    tags TEXT[],
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);
```

### 2.4 外部API集成层

#### 2.4.1 股票数据源配置
```python
# 示例：Alpha Vantage API集成
import requests
from typing import Optional, Dict, Any

class AlphaVantageAPI:
    def __init__(self, api_key: str):
        self.api_key = api_key
        self.base_url = "https://www.alphavantage.co/query"
        
    def get_daily_data(self, symbol: str, outputsize: str = "compact") -> Optional[Dict[str, Any]]:
        """
        获取股票每日数据
        """
        params = {
            "function": "TIME_SERIES_DAILY",
            "symbol": symbol,
            "outputsize": outputsize,
            "apikey": self.api_key
        }
        
        try:
            response = requests.get(self.base_url, params=params)
            response.raise_for_status()
            return response.json()
        except Exception as e:
            print(f"Error fetching daily data for {symbol}: {str(e)}")
            return None
            
    def get_quote_endpoint(self, symbol: str) -> Optional[Dict[str, Any]]:
        """
        获取股票实时报价
        """
        params = {
            "function": "GLOBAL_QUOTE",
            "symbol": symbol,
            "apikey": self.api_key
        }
        
        try:
            response = requests.get(self.base_url, params=params)
            response.raise_for_status()
            return response.json()
        except Exception as e:
            print(f"Error fetching quote for {symbol}: {str(e)}")
            return None
            
    def get_income_statement(self, symbol: str) -> Optional[Dict[str, Any]]:
        """
        获取利润表数据
        """
        params = {
            "function": "INCOME_STATEMENT",
            "symbol": symbol,
            "apikey": self.api_key
        }
        
        try:
            response = requests.get(self.base_url, params=params)
            response.raise_for_status()
            return response.json()
        except Exception as e:
            print(f"Error fetching income statement for {symbol}: {str(e)}")
            return None
```

## 3. 关键功能实现方案

### 3.1 数据同步机制
```python
# 示例：定时数据同步任务
import schedule
import time
from datetime import datetime, timedelta
from services.data_sync_service import DataSyncService
from database import get_db

def sync_stock_data_task():
    """
    定时同步股票数据
    """
    print(f"Starting stock data sync at {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    db = next(get_db())
    sync_service = DataSyncService(db)
    
    try:
        # 获取所有用户的自选股
        user_stocks = sync_service.get_all_user_stocks()
        
        # 按用户同步数据
        for user_stock in user_stocks:
            try:
                sync_service.sync_stock_data_for_user(user_stock.user_id, user_stock.stock_id)
            except Exception as e:
                print(f"Error syncing stock {user_stock.stock_id} for user {user_stock.user_id}: {str(e)}")
                
        print(f"Stock data sync completed at {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    except Exception as e:
        print(f"Error in stock data sync task: {str(e)}")
    finally:
        db.close()

def sync_financial_data_task():
    """
    定时同步财务数据
    """
    print(f"Starting financial data sync at {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    db = next(get_db())
    sync_service = DataSyncService(db)
    
    try:
        # 获取所有用户的自选股
        user_stocks = sync_service.get_all_user_stocks()
        
        # 按用户同步数据
        for user_stock in user_stocks:
            try:
                sync_service.sync_financial_data_for_user(user_stock.user_id, user_stock.stock_id)
            except Exception as e:
                print(f"Error syncing financial data for stock {user_stock.stock_id} for user {user_stock.user_id}: {str(e)}")
                
        print(f"Financial data sync completed at {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    except Exception as e:
        print(f"Error in financial data sync task: {str(e)}")
    finally:
        db.close()

# 配置任务调度
schedule.every().day.at("18:30").do(sync_stock_data_task)  # 每日收盘后同步
schedule.every(7).days.do(sync_financial_data_task)  # 每周同步财务数据

def run_scheduler():
    print("Scheduler started")
    while True:
        schedule.run_pending()
        time.sleep(60)  # 每分钟检查一次任务
```

### 3.2 规则引擎执行流程
```python
# 示例：规则引擎执行流程
from services.rule_engine_service import RuleEngine
from database import get_db

def run_analysis_rules():
    """
    执行所有分析规则
    """
    print(f"Starting rule analysis at {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    db = next(get_db())
    rule_engine = RuleEngine(db)
    
    try:
        # 获取所有启用的规则
        enabled_rules = rule_engine.get_enabled_rules()
        
        # 获取需要分析的股票数据
        stocks_to_analyze = rule_engine.get_stocks_to_analyze()
        
        # 执行规则分析
        analysis_results = []
        for rule in enabled_rules:
            for stock in stocks_to_analyze:
                try:
                    stock_data = rule_engine.get_stock_analysis_data(stock.id)
                    if rule_engine.evaluate_rule(rule, stock.code, stock_data):
                        analysis_results.append({
                            "rule_id": rule.id,
                            "stock_id": stock.id,
                            "timestamp": datetime.now(),
                            "data": stock_data
                        })
                except Exception as e:
                    print(f"Error evaluating rule {rule.id} for stock {stock.code}: {str(e)}")
        
        # 保存分析结果
        rule_engine.save_analysis_results(analysis_results)
        
        # 发送通知
        rule_engine.send_analysis_notifications(analysis_results)
        
        print(f"Rule analysis completed at {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    except Exception as e:
        print(f"Error in rule analysis: {str(e)}")
    finally:
        db.close()

# 配置分析任务调度
schedule.every().day.at("19:00").do(run_analysis_rules)  # 数据同步后执行分析
```

### 3.3 文件上传与管理
```python
# 示例：文件上传与管理
import os
import uuid
from fastapi import UploadFile, File, Depends
from sqlalchemy.orm import Session
from . import crud, schemas, dependencies

async def upload_file(
    file: UploadFile = File(...),
    stock_id: int = None,
    tags: str = None,
    db: Session = Depends(dependencies.get_db),
    current_user: dict = Depends(dependencies.get_current_user)
):
    """
    上传文件
    """
    # 生成唯一文件名
    file_extension = os.path.splitext(file.filename)[1]
    unique_filename = f"{uuid.uuid4()}{file_extension}"
    
    # 确保目录存在
    upload_dir = "uploads"
    os.makedirs(upload_dir, exist_ok=True)
    
    # 保存文件
    file_path = os.path.join(upload_dir, unique_filename)
    with open(file_path, "wb") as f:
        f.write(await file.read())
    
    # 解析标签
    tag_list = tags.split(",") if tags else []
    
    # 保存到数据库
    db_file = crud.create_uploaded_file(
        db,
        user_id=current_user["id"],
        stock_id=stock_id,
        file_name=file.filename,
        file_type=file.content_type,
        file_path=file_path,
        file_size=os.path.getsize(file_path),
        tags=tag_list
    )
    
    return schemas.UploadedFileResponse(
        id=db_file.id,
        file_name=db_file.file_name,
        file_type=db_file.file_type,
        file_path=db_file.file_path,
        file_size=db_file.file_size,
        tags=db_file.tags,
        created_at=db_file.created_at
    )
```

## 4. 性能优化方案

### 4.1 数据缓存策略
```python
# 示例：Redis缓存实现
import redis
import json
from typing import Optional, Any
from datetime import timedelta

class RedisCache:
    def __init__(self, host: str = "localhost", port: int = 6379, db: int = 0):
        self.client = redis.Redis(host=host, port=port, db=db, decode_responses=True)
        
    def set(self, key: str, value: Any, expires_in: timedelta = None):
        """
        设置缓存
        """
        if expires_in:
            self.client.setex(key, expires_in, json.dumps(value))
        else:
            self.client.set(key, json.dumps(value))
            
    def get(self, key: str) -> Optional[Any]:
        """
        获取缓存
        """
        value = self.client.get(key)
        if value:
            try:
                return json.loads(value)
            except Exception as e:
                print(f"Error decoding cached value for key {key}: {str(e)}")
                return None
        return None
            
    def delete(self, key: str):
        """
        删除缓存
        """
        self.client.delete(key)
            
    def clear(self, pattern: str = "*"):
        """
        清除符合模式的所有缓存
        """
        for key in self.client.scan_iter(pattern):
            self.client.delete(key)
            
    # 股票数据缓存方法
    def set_stock_data(self, stock_code: str, data: dict, expires_in: timedelta = timedelta(hours=1)):
        """
        缓存股票数据
        """
        self.set(f"stock:{stock_code}:data", data, expires_in)
        
    def get_stock_data(self, stock_code: str) -> Optional[dict]:
        """
        获取股票数据缓存
        """
        return self.get(f"stock:{stock_code}:data")
        
    # 分析结果缓存方法
    def set_analysis_results(self, rule_id: int, stock_code: str, results: list, expires_in: timedelta = timedelta(days=1)):
        """
        缓存分析结果
        """
        self.set(f"analysis:{rule_id}:{stock_code}", results, expires_in)
        
    def get_analysis_results(self, rule_id: int, stock_code: str) -> Optional[list]:
        """
        获取分析结果缓存
        """
        return self.get(f"analysis:{rule_id}:{stock_code}")
```

### 4.2 数据库优化
```sql
-- 创建索引以优化查询
CREATE INDEX idx_user_stocks_user_id ON user_stocks(user_id);
CREATE INDEX idx_user_stocks_stock_id ON user_stocks(stock_id);
CREATE INDEX idx_investment_notes_user_stock ON investment_notes(user_id, stock_id);
CREATE INDEX idx_uploaded_files_user_stock ON uploaded_files(user_id, stock_id);
CREATE INDEX idx_investment_notes_tags ON investment_notes USING GIN(tags);
CREATE INDEX idx_uploaded_files_tags ON uploaded_files USING GIN(tags);

-- 时序数据查询优化示例
-- 使用InfluxDB的GROUP BY和时间窗口查询
SELECT mean("close") AS "close", mean("volume") AS "volume" 
FROM "stock_trades" 
WHERE time > now() - 30d AND "code" = 'AAPL' 
GROUP BY time(1d), "code"
```

### 4.3 前端性能优化
```javascript
// 示例：前端数据懒加载与虚拟滚动
import React, { useState, useEffect, useRef } from 'react';
import StockCard from './StockCard';
import { fetchStockList } from '../services/api';

const StockList: React.FC = () => {
  const [stocks, setStocks] = useState([]);
  const [loading, setLoading] = useState(false);
  const [page, setPage] = useState(1);
  const [hasMore, setHasMore] = useState(true);
  const observerRef = useRef(null);
  
  useEffect(() => {
    loadStocks();
  }, [page]);
  
  const loadStocks = async () => {
    if (loading || !hasMore) return;
    
    setLoading(true);
    try {
      const newStocks = await fetchStockList(page, 20);
      
      if (newStocks.length < 20) {
        setHasMore(false);
      }
      
      setStocks(prevStocks => [...prevStocks, ...newStocks]);
    } catch (error) {
      console.error('Failed to load stocks:', error);
    } finally {
      setLoading(false);
    }
  };
  
  const handleObserver = (entries: IntersectionObserverEntry[]) => {
    const target = entries[0];
    if (target.isIntersecting && hasMore && !loading) {
      setPage(prevPage => prevPage + 1);
    }
  };
  
  useEffect(() => {
    const observer = new IntersectionObserver(handleObserver, {
      root: null,
      rootMargin: '200px',
      threshold: 0.1
    });
    
    if (observerRef.current) {
      observer.observe(observerRef.current);
    }
    
    return () => {
      if (observerRef.current) {
        observer.unobserve(observerRef.current);
      }
    };
  }, [hasMore, loading]);
  
  return (
    <div className="stock-list">
      <div className="grid grid-cols-1 md:grid-cols-2 lg:grid-cols-3 gap-4">
        {stocks.map(stock => (
          <StockCard key={stock.code} stock={stock} onClick={() => console.log('Stock clicked:', stock)} />
        ))}
      </div>
      
      {loading && (
        <div className="flex justify-center py-8">
          <div className="animate-spin rounded-full h-12 w-12 border-b-2 border-blue-600"></div>
        </div>
      )}
      
      {!loading && !hasMore && (
        <div className="text-center py-8 text-gray-500">
          已加载全部股票数据
        </div>
      )}
      
      <div ref={observerRef} style={{ height: '20px' }} />
    </div>
  );
};

export default StockList;
```

## 5. 安全性设计

### 5.1 用户认证与授权
```python
# 示例：JWT认证实现
from fastapi import Depends, HTTPException, status
from fastapi.security import OAuth2PasswordBearer
from jose import JWTError, jwt
from datetime import datetime, timedelta
from typing import Optional
from . import schemas, crud, dependencies

SECRET_KEY = "your-secret-key-here"
ALGORITHM = "HS256"
ACCESS_TOKEN_EXPIRE_MINUTES = 30

oauth2_scheme = OAuth2PasswordBearer(tokenUrl="token")

def create_access_token(data: dict, expires_delta: Optional[timedelta] = None):
    """
    创建访问令牌
    """
    to_encode = data.copy()
    if expires_delta:
        expire = datetime.utcnow() + expires_delta
    else:
        expire = datetime.utcnow() + timedelta(minutes=ACCESS_TOKEN_EXPIRE_MINUTES)
    to_encode.update({"exp": expire})
    encoded_jwt = jwt.encode(to_encode, SECRET_KEY, algorithm=ALGORITHM)
    return encoded_jwt

async def get_current_user(token: str = Depends(oauth2_scheme), db: Session = Depends(dependencies.get_db)):
    """
    获取当前用户
    """
    credentials_exception = HTTPException(
        status_code=status.HTTP_401_UNAUTHORIZED,
        detail="Could not validate credentials",
        headers={"WWW-Authenticate": "Bearer"},
    )
    
    try:
        payload = jwt.decode(token, SECRET_KEY, algorithms=[ALGORITHM])
        username: str = payload.get("sub")
        if username is None:
            raise credentials_exception
        token_data = schemas.TokenData(username=username)
    except JWTError:
        raise credentials_exception
        
    user = crud.get_user_by_username(db, username=token_data.username)
    if user is None:
        raise credentials_exception
        
    return user

async def get_current_active_user(current_user: schemas.User = Depends(get_current_user)):
    """
    获取当前活跃用户
    """
    if current_user.disabled:
        raise HTTPException(status_code=400, detail="Inactive user")
    return current_user
```

### 5.2 文件安全处理
```python
# 示例：文件安全检查与处理
import os
import magic
import hashlib
from typing import Optional

def validate_uploaded_file(file_path: str, allowed_types: list = None) -> bool:
    """
    验证上传文件的安全性
    """
    if allowed_types is None:
        allowed_types = ["application/pdf", "application/msword", "application/vnd.ms-excel",
                       "application/vnd.openxmlformats-officedocument.wordprocessingml.document",
                       "application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"]
        
    try:
        # 检查文件类型
        detected_type = magic.from_file(file_path, mime=True)
        if detected_type not in allowed_types:
            print(f"Invalid file type: {detected_type}")
            return False
            
        # 检查文件大小（限制为10MB）
        file_size = os.path.getsize(file_path)
        if file_size > 10 * 1024 * 1024:
            print(f"File too large: {file_size} bytes")
            return False
            
        # 检查是否包含恶意内容（简单示例）
        with open(file_path, "rb") as f:
            content = f.read()
            
        # 检查是否包含常见的恶意代码签名
        malicious_signatures = [
            b"eval(", b"document.write(", b"<script>", b"javascript:"
        ]
        
        for signature in malicious_signatures:
            if signature in content:
                print("File contains malicious content")
                return False
                
        return True
    except Exception as e:
        print(f"Error validating file: {str(e)}")
        return False
        
def calculate_file_hash(file_path: str, hash_algorithm: str = "sha256") -> Optional[str]:
    """
    计算文件哈希值
    """
    try:
        hash_obj = hashlib.new(hash_algorithm)
        with open(file_path, "rb") as f:
            for chunk in iter(lambda: f.read(4096), b""):
                hash_obj.update(chunk)
        return hash_obj.hexdigest()
    except Exception as e:
        print(f"Error calculating file hash: {str(e)}")
        return None
```

## 6. 部署与运维

### 6.1 容器化部署
```yaml
# docker-compose.yml示例
version: '3.8'

services:
  web:
    build: ./frontend
    ports:
      - "3000:3000"
    depends_on:
      - api
    environment:
      - REACT_APP_API_BASE_URL=http://localhost:8000
    restart: unless-stopped

  api:
    build: ./backend
    ports:
      - "8000:8000"
    depends_on:
      - db
      - redis
      - influxdb
    environment:
      - DATABASE_URL=postgresql://postgres:password@db:5432/stock_analysis
      - REDIS_URL=redis://redis:6379/0
      - INFLUXDB_URL=http://influxdb:8086
    restart: unless-stopped

  db:
    image: postgres:13
    ports:
      - "5432:5432"
    environment:
      - POSTGRES_USER=postgres
      - POSTGRES_PASSWORD=password
      - POSTGRES_DB=stock_analysis
    volumes:
      - postgres_data:/var/lib/postgresql/data
    restart: unless-stopped

  redis:
    image: redis:alpine
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    restart: unless-stopped

  influxdb:
    image: influxdb:2.0
    ports:
      - "8086:8086"
    environment:
      - DOCKER_INFLUXDB_INIT_MODE=setup
      - DOCKER_INFLUXDB_INIT_USERNAME=admin
      - DOCKER_INFLUXDB_INIT_PASSWORD=password
      - DOCKER_INFLUXDB_INIT_ORG=stock_analysis
      - DOCKER_INFLUXDB_INIT_BUCKET=stock_trades
    volumes:
      - influxdb_data:/var/lib/influxdb2
    restart: unless-stopped

  minio:
    image: minio/minio
    ports:
      - "9000:9000"
      - "9001:9001"
    environment:
      - MINIO_ROOT_USER=minioadmin
      - MINIO_ROOT_PASSWORD=minioadmin
    volumes:
      - minio_data:/data
    command: server --console-address ":9001" /data
    restart: unless-stopped

volumes:
  postgres_data:
  redis_data:
  influxdb_data:
  minio_data:
```

### 6.2 日志与监控
```python
# 示例：日志配置
import logging
from logging.handlers import RotatingFileHandler
import os

def setup_logging():
    """
    配置日志系统
    """
    log_dir = "logs"
    os.makedirs(log_dir, exist_ok=True)
    
    # 主日志文件
    main_log_file = os.path.join(log_dir, "app.log")
    
    # 设置日志级别
    logging.basicConfig(level=logging.INFO)
    
    # 创建格式化器
    formatter = logging.Formatter(
        "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
    )
    
    # 文件日志处理器（按大小旋转）
    file_handler = RotatingFileHandler(
        main_log_file,
        maxBytes=10 * 1024 * 1024,  # 10MB
        backupCount=5,
        encoding="utf-8"
    )
    file_handler.setLevel(logging.INFO)
    file_handler.setFormatter(formatter)
    
    # 控制台日志处理器
    console_handler = logging.StreamHandler()
    console_handler.setLevel(logging.DEBUG)
    console_handler.setFormatter(formatter)
    
    # 获取根记录器
    root_logger = logging.getLogger()
    root_logger.addHandler(file_handler)
    root_logger.addHandler(console_handler)
    
    # 配置其他模块的日志级别
    logging.getLogger("sqlalchemy").setLevel(logging.WARNING)
    logging.getLogger("urllib3").setLevel(logging.WARNING)

# 示例：监控指标收集
from prometheus_client import Gauge, Histogram, Counter

# 请求指标
REQUESTS_TOTAL = Counter('api_requests_total', 'Total number of API requests', ['method', 'endpoint', 'status_code'])
REQUEST_DURATION = Histogram('api_request_duration_seconds', 'Duration of API requests', ['method', 'endpoint'])

# 数据同步指标
SYNC_TOTAL = Counter('data_sync_total', 'Total number of data sync operations', ['type', 'status'])
SYNC_DURATION = Histogram('data_sync_duration_seconds', 'Duration of data sync operations', ['type'])
SYNC_FAILURES = Counter('data_sync_failures_total', 'Number of failed data sync operations', ['type', 'reason'])

# 分析规则指标
RULE_EXECUTIONS = Counter('rule_executions_total', 'Total number of rule executions', ['rule_id', 'stock_code', 'result'])
RULE_EXECUTION_DURATION = Histogram('rule_execution_duration_seconds', 'Duration of rule executions', ['rule_id', 'stock_code'])
RULE_TRIGGERS = Counter('rule_triggers_total', 'Number of rule triggers', ['rule_id', 'stock_code'])
```

## 7. 扩展方案

### 7.1 AI增强分析
```python
# 示例：简单的AI分析接口
import numpy as np
import pandas as pd
from sklearn.linear_model import LinearRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error

class AIAnalysisService:
    def __init__(self, db_session):
        self.db = db_session
        
    def predict_stock_price(self, stock_code: str, days: int = 7) -> dict:
        """
        预测股票价格
        """
        # 获取历史数据
        historical_data = self._get_stock_historical_data(stock_code)
        
        if len(historical_data) < 30:
            return {
                "code": stock_code,
                "prediction": None,
                "confidence": 0,
                "message": "Insufficient historical data"
            }
            
        # 准备训练数据
        data = pd.DataFrame(historical_data)
        data['Date'] = pd.to_datetime(data['Date'])
        data['Date_Ordinal'] = data['Date'].apply(lambda x: x.toordinal())
        
        X = data[['Date_Ordinal']]
        y = data['Close']
        
        # 训练模型
        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
        
        model = LinearRegression()
        model.fit(X_train, y_train)
        
        # 进行预测
        future_dates = pd.date_range(data['Date'].max(), periods=days+1)[1:]
        future_dates_ordinal = future_dates.apply(lambda x: x.toordinal()).values.reshape(-1, 1)
        
        predictions = model.predict(future_dates_ordinal)
        
        # 评估模型
        y_pred = model.predict(X_test)
        rmse = np.sqrt(mean_squared_error(y_test, y_pred))
        confidence = max(0, 1 - rmse / np.mean(y))
        
        # 准备结果
        prediction_result = {
            "code": stock_code,
            "prediction": [
                {
                    "date": date.strftime("%Y-%m-%d"),
                    "price": round(float(price), 2)
                }
                for date, price in zip(future_dates, predictions)
            ],
            "confidence": round(confidence, 2),
            "message": f"Prediction generated using linear regression"
        }
        
        return prediction_result
        
    def analyze_sentiment(self, stock_code: str) -> dict:
        """
        分析市场情绪（模拟实现）
        """
        # 在真实场景中，这应该调用新闻/社交媒体API
        import random
        
        sentiments = ["positive", "neutral", "negative"]
        probabilities = [0.4, 0.4, 0.2]
        
        sentiment = random.choices(sentiments, weights=probabilities)[0]
        
        return {
            "code": stock_code,
            "sentiment": sentiment,
            "confidence": round(random.uniform(0.6, 0.9), 2),
            "message": f"Sentiment analysis based on recent news and social media"
        }
```

## 8. 系统启动与运行

### 8.1 本地开发环境
```bash
# 1. 克隆仓库
git clone <repository-url>
cd stockTrade

# 2. 创建虚拟环境
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate

# 3. 安装依赖
pip install -r requirements.txt

# 4. 初始化数据库
python -m app.database.init_db

# 5. 启动后端服务
uvicorn app.main:app --reload --host 0.0.0.0 --port 8000

# 6. 启动前端服务（另一个终端）
cd frontend
npm install
npm start

# 7. 启动调度任务（另一个终端）
python -m app.scheduler.start
```

### 8.2 生产环境部署
```bash
# 1. 构建镜像
docker-compose build

# 2. 启动服务
docker-compose up -d

# 3. 初始化数据库
docker exec -it stocktrade_db_1 createdb -U postgres stock_analysis

# 4. 运行数据库迁移
docker exec -it stocktrade_api_1 python -m app.database.init_db

# 5. 检查服务状态
docker-compose ps

# 6. 查看日志
docker-compose logs -f web api db redis
```

## 总结

本系统设计采用了现代化的技术栈和架构模式，实现了股票数据获取、智能分析、深度研究与个人知识管理的一体化平台。通过前后端分离架构和模块化设计，系统具有良好的可扩展性和可维护性。关键功能如数据同步、规则引擎、档案管理等都有详细的实现方案，并考虑了性能优化、安全性和运维监控等方面的设计。

系统架构的各个层次相互协作，形成了一个完整的股票深度分析系统，为用户提供了从数据获取到投资决策的全流程支持。
```

        
            
toolName: view_files
            
status: success
          
            
filePath: c:\Users\abot\workspace\trade\stockTrade\股票深度分析系统_PRD.md
          
我已经根据PRD文档创建了一份详细的系统设计文档。这份设计文档包含了以下几个核心部分：

1. **系统架构概述**：设计了一个前后端分离的现代化架构，包含前端展示层、后端服务层、数据存储层和外部API集成层。

2. **系统模块详细设计**：
   - 前端展示层：设计了响应式界面，包含仪表盘、股票档案库、分析规则引擎等核心页面
   - 后端服务层：设计了API网关、用户认证服务、数据同步服务、规则引擎服务等
   - 数据存储层：设计了关系型数据库、时序数据库、对象存储和缓存
   - 外部API集成层：支持多个股票数据API，如Alpha Vantage、Finnhub等

3. **关键功能实现方案**：
   - 数据同步机制：实现了定时同步任务
   - 规则引擎执行流程：设计了条件评估和复合规则处理
   - 文件上传与管理：实现了安全的文件上传和下载功能

4. **性能优化方案**：
   - 数据缓存策略：使用Redis缓存热点数据
   - 数据库优化：设计了合理的索引和查询优化
   - 前端性能优化：实现了数据懒加载和虚拟滚动

5. **安全性设计**：
   - 用户认证与授权：实现了JWT认证
   - 文件安全处理：添加了文件类型检查和内容验证

6. **部署与运维**：提供了Docker容器化部署方案和日志监控系统

7. **扩展方案**：考虑了AI增强分析功能，如股票价格预测和情绪分析

8. **系统启动与运行**：提供了本地开发环境和生产环境部署指南

这份系统设计文档与PRD文档紧密对应，确保了功能的完整性和架构的合理性。您可以根据这个设计文档来实施项目开发。

您希望我继续帮您创建项目的基础架构文件，如package.json、requirements.txt、docker-compose.yml等吗？或者您有其他特定的技术要求需要调整？